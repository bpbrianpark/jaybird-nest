FROM python:3.10-slim

WORKDIR /app

# Install PyTorch CPU-only version first 
RUN pip install --no-cache-dir \
    torch torchvision --index-url https://download.pytorch.org/whl/cpu

# Install production requirements (without torch/torchvision)
COPY ml/requirements-prod.txt ./requirements-prod.txt
RUN pip install --no-cache-dir -r requirements-prod.txt

# Copy the model registry (needed for inference)
COPY model_registry/ ./model_registry/

# Copy the inference service code
COPY ml/inference/ ./ml/inference/

# Set PYTHONPATH so imports work
ENV PYTHONPATH=/app

EXPOSE 8000

# Run the FastAPI service
CMD ["uvicorn", "ml.inference.predictor:app", "--host", "0.0.0.0", "--port", "8000"]